# ğŸ“Š Change Point Analysis and Statistical Modeling of Brent Oil Prices

**10 Academy â€“ Artificial Intelligence Mastery**
**Week 11: Time Series Analysis Challenge**
ğŸ“… *04 Feb â€“ 10 Feb 2026*

---

## ğŸ“Œ Project Overview

This project analyzes **Brent crude oil price dynamics** using **time series analysis** and **Bayesian change point detection** to identify structural breaks and relate them to major geopolitical, economic, and policy-driven events.

The analysis is conducted in the context of **Birhan Energies**, a data-driven energy consultancy, to support **investors, policymakers, and energy companies** in understanding market instability and making informed decisions.

**Task 1** lays the analytical foundation by:

* Defining a clear, reproducible data analysis workflow
* Exploring statistical properties of the data
* Compiling and aligning major global events with price movements
* Documenting assumptions, limitations, and communication strategies

---

## ğŸ¯ Objectives

### Overall Project Goals

* Identify key political and economic events impacting Brent oil prices
* Quantify regime shifts using Bayesian change point models
* Translate statistical findings into actionable insights

### Task 1 Objectives

* Define and document the full data analysis workflow
* Perform exploratory and statistical analysis of Brent oil prices
* Prepare data for Bayesian change point modeling
* Compile a structured event dataset (10â€“15 key events)
* Clearly state assumptions, limitations, and communication channels

---

## ğŸ—‚ï¸ Repository Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original datasets (ignored by Git)
â”‚   â””â”€â”€ processed/          # Cleaned and transformed data
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ workflow.md         # Explicit Task 1 analysis workflow
â”‚   â”œâ”€â”€ assumptions.md     # Assumptions & limitations
â”‚   â””â”€â”€ events.csv         # Tabular geopolitical & economic events
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ task1_eda.ipynb     # Exploratory Data Analysis (Task 1)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py     # Modular data loading & validation
â”‚   â”œâ”€â”€ preprocessing.py  # Transformations & feature engineering
â”‚   â””â”€â”€ utils.py           # Shared utilities & error handling
â”‚
â”œâ”€â”€ backend/               # Flask backend (Task 3)
â”œâ”€â”€ frontend/              # React dashboard (Task 3)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

âœ”ï¸ **Addresses feedback**: explicit workflow documentation, tabular event dataset, and modular Python code with basic error handling.

---

## ğŸ” Data Analysis Workflow (Task 1)

The workflow is fully documented in **`docs/workflow.md`** and implemented as follows:

### 1. Data Loading

* Load historical Brent oil price data
* Parse dates and enforce correct data types
* Validate schema and date continuity

### 2. Data Quality Checks

* Detect missing values and duplicates
* Verify price validity (non-negative, realistic ranges)

### 3. Exploratory Data Analysis (EDA)

* Visualize long-term price trends
* Identify volatility clustering and shocks

### 4. Time Series Transformation

* Compute log returns to stabilize variance
* Prepare data for stationarity testing

### 5. Stationarity Testing

* Apply Augmented Dickey-Fuller (ADF) test
* Confirm suitability for statistical modeling

### 6. Volatility Analysis

* Examine clustering behavior typical of financial time series

### 7. Event Overlay Analysis

* Align geopolitical and economic events with price movements
* Visualize temporal correspondence

### 8. Data Export

* Save cleaned and transformed datasets for modeling and dashboards

---

## ğŸ“ˆ Time Series Properties Analysis

### Trend

* Raw Brent prices exhibit strong long-term trends
* Influenced by macroeconomic conditions, conflicts, and policy shifts
* Non-stationary in price levels

### Stationarity

ADF test applied to log returns:

* **ADF Statistic:** -16.43
* **p-value:** 2.49e-29

âœ… Log returns are stationary and suitable for Bayesian modeling.

### Volatility

* Clear volatility clustering observed
* Supports regime-based and change point modeling approaches

---

## ğŸŒ Event Data Compilation

A structured dataset of major global events was manually researched and compiled.

### Event Categories

* Geopolitical conflicts (e.g., Gulf War, Libya Civil War)
* OPEC production decisions
* Global economic crises (e.g., 2008 Financial Crisis)
* Political upheavals (e.g., Arab Spring)
* Sanctions and policy shifts

### Event Fields

* Event name
* Approximate start date
* Event type/category

ğŸ“ **Stored at:** `docs/events.csv`
ğŸ“Š **Used for:** Visual alignment and hypothesis generation (not causal proof)

---

## ğŸ” Change Point Modeling â€“ Conceptual Overview

Change point models identify **structural breaks** in time series data.

In this project, they are used to detect:

* Shifts in mean price behavior
* Market regime changes
* Structural breaks potentially associated with major events

### Expected Outputs

* **Ï„ (tau):** Estimated timing of regime change
* **Î¼â‚, Î¼â‚‚:** Mean log returns before and after the change
* **Uncertainty:** Credible intervals for timing and magnitude

### Limitations

* Change points may not align exactly with known events
* Temporal correlation â‰  causal impact
* Results are sensitive to model assumptions

---

## âš ï¸ Assumptions and Limitations

### Assumptions

* Event start dates are approximate
* Market reactions may be delayed
* Log returns sufficiently capture price dynamics

### Limitations

* Correlation does not imply causation
* External drivers (speculation, FX rates) are not modeled
* Daily prices miss intraday dynamics
* Noise and model priors affect detection sensitivity

ğŸ“„ Full discussion available in **`docs/assumptions.md`**

---

## ğŸ“¢ Communication Strategy

Results are communicated through:

* **Technical reports** for analysts and policymakers
* **Interactive dashboards** for investors and energy firms
* **Visual narratives** highlighting regime shifts
* **Plain-language summaries** translating Bayesian results into insights

---

## âœ… Task 1 Deliverables Status

| Requirement                    | Status      |
| ------------------------------ | ----------- |
| Defined analysis workflow      | âœ… Completed |
| Workflow documentation         | âœ… Completed |
| Event dataset (10â€“15 events)   | âœ… Completed |
| Trend analysis                 | âœ… Completed |
| Stationarity testing           | âœ… Completed |
| Volatility analysis            | âœ… Completed |
| Change point model explanation | âœ… Completed |
| Assumptions & limitations      | âœ… Completed |
| Modular Python code            | âœ… Completed |
| Communication strategy         | âœ… Completed |

---

## ğŸš€ Next Steps (Task 2 & 3)

### Task 2

* Implement Bayesian change point detection using PyMC
* Quantify regime shifts with posterior distributions
* Associate detected changes with plausible events

### Task 3

* Develop Flask APIs to serve analysis outputs
* Build React dashboards with interactive event overlays
* Enable filtering, drill-downs, and stakeholder exploration

---

## ğŸ“š References

Key references on data science workflows, Bayesian inference, and change point detection are listed in the challenge documentation and were actively used to guide this work.

---
